<<<<<<< Updated upstream
out <- ode(y = init.state, func = amr, times = seq(0, 1000), parms = thetaparm)
View(out)
library("deSolve"); library("ggplot2"); library("plotly"); library("reshape2")
library("bayestestR"); library("tmvtnorm"); library("ggpubr"); library("rootSolve")
=======
"usage_amp" = rowMeans(usage_broil[,22:25], na.rm = TRUE),
"usage_tet" = rowMeans(usage_broil[,26:29], na.rm = TRUE),
"N" = rowSums(amp_broil[,2:5], na.rm = TRUE),
"isolpos_amp" = rowSums(amp_broil[,6:9], na.rm = TRUE),
"isolpos_tet" = rowSums(tet_broil[,6:9], na.rm = TRUE))
broil_rel$propres_amp <- broil_rel$isolpos_amp /  broil_rel$N
broil_rel$propres_tet <- broil_rel$isolpos_tet /  broil_rel$N
broil_rel$propres_amp_trans <- ((broil_rel$propres_amp*(nrow(broil_rel)-1)) + 0.5)/nrow(broil_rel)
broil_rel$propres_tet_trans <- ((broil_rel$propres_tet*(nrow(broil_rel)-1)) + 0.5)/nrow(broil_rel)
broil_rel$lower_amp <- unlist(lapply(1:nrow(broil_rel), function(i) prop.test(broil_rel$isolpos_amp[i],broil_rel$N[i])[[6]][[1]]))
broil_rel$upper_amp <- unlist(lapply(1:nrow(broil_rel), function(i) prop.test(broil_rel$isolpos_amp[i],broil_rel$N[i])[[6]][[2]]))
broil_rel$lower_tet <- unlist(lapply(1:nrow(broil_rel), function(i) prop.test(broil_rel$isolpos_tet[i],broil_rel$N[i])[[6]][[1]]))
broil_rel$upper_tet <- unlist(lapply(1:nrow(broil_rel), function(i) prop.test(broil_rel$isolpos_tet[i],broil_rel$N[i])[[6]][[2]]))
#Stat Test
broil_stat_amp <- betareg(propres_amp_trans ~ usage_amp, broil_rel)
broil_stat_tet <- betareg(propres_tet_trans ~ usage_tet, data = broil_rel)
summary(broil_stat_amp)
summary(broil_stat_tet)
broil_amp <- ggplot(broil_rel, aes(x = usage_amp, y = propres_amp)) + geom_point() + theme_bw() +
geom_line(aes(y = predict(broil_stat_amp, broil_rel), x = usage_amp), colour = "red", size = 1.2) +
geom_errorbar(aes(ymin=lower_amp, ymax=upper_amp),  size=0.5, width = 0) +
labs(title = "Ampicillin Usage in Broilers: 2014-2018", x = "Ampicillin Usage", y = "Proportion Broilers Resistant")
broil_tet <- ggplot(broil_rel, aes(x = usage_tet, y = propres_tet)) + geom_point() + theme_bw() +
geom_line(aes(y = predict(broil_stat_tet, broil_rel), x = usage_tet), colour = "red", size = 1.2) +
geom_errorbar(aes(ymin=lower_tet, ymax=upper_tet),  size=0.5, width = 0)+
labs(title = "Tetracycline Usage in Broilers: 2014-2018", x = "Tetracycline Usage", y = "Proportion Broilers Resistant")
# Stat Testing - FATTENING PIGS -------------------------------------------------------------
pig_rel <- data.frame("Country" = usage_pigs$Country,
"usage_amp" = rowMeans(usage_pigs[,27:31], na.rm = TRUE),
"usage_tet" = rowMeans(usage_pigs[,32:36], na.rm = TRUE),
"N" = rowSums(amp_pigs[,2:6], na.rm = TRUE),
"isolpos_amp" = rowSums(amp_pigs[,7:11], na.rm = TRUE),
"isolpos_tet" = rowSums(tet_pigs[,7:11], na.rm = TRUE))
pig_rel$propres_amp <- pig_rel$isolpos_amp /  pig_rel$N
pig_rel$propres_tet <- pig_rel$isolpos_tet /  pig_rel$N
pig_rel$propres_amp_trans <- ((pig_rel$propres_amp*(nrow(pig_rel)-1)) + 0.5)/nrow(pig_rel)
pig_rel$propres_tet_trans <- ((pig_rel$propres_tet*(nrow(pig_rel)-1)) + 0.5)/nrow(pig_rel)
pig_rel$lower_amp <- unlist(lapply(1:nrow(pig_rel), function(i) prop.test(pig_rel$isolpos_amp[i],pig_rel$N[i])[[6]][[1]]))
pig_rel$upper_amp <- unlist(lapply(1:nrow(pig_rel), function(i) prop.test(pig_rel$isolpos_amp[i],pig_rel$N[i])[[6]][[2]]))
pig_rel$lower_tet <- unlist(lapply(1:nrow(pig_rel), function(i) prop.test(pig_rel$isolpos_tet[i],pig_rel$N[i])[[6]][[1]]))
pig_rel$upper_tet <- unlist(lapply(1:nrow(pig_rel), function(i) prop.test(pig_rel$isolpos_tet[i],pig_rel$N[i])[[6]][[2]]))
#Stat Test
pig_stat_amp <- betareg(propres_amp_trans ~ usage_amp, pig_rel)
pig_stat_tet <- betareg(propres_tet_trans ~ usage_tet, data = pig_rel)
summary(pig_stat_amp)
summary(pig_stat_tet)
pig_amp <- ggplot(pig_rel, aes(x = usage_amp, y = propres_amp)) + geom_point() + theme_bw() +
geom_line(aes(y = predict(pig_stat_amp, pig_rel), x = usage_amp), colour = "red", size = 1.2) +
scale_y_continuous(limits = c(0,1)) +
geom_errorbar(aes(ymin=lower_amp, ymax=upper_amp),  size=0.5, width = 0) +
labs(title = "Ampicillin Usage in Fat Pigs: 2015-2019", x = "Ampicillin Usage", y = "Proportion Pigs Resistant")
pig_tet <- ggplot(pig_rel, aes(x = usage_tet, y = propres_tet)) + geom_point() + theme_bw() +
geom_line(aes(y = predict(pig_stat_tet, pig_rel), x = usage_tet), colour = "red", size = 1.2) +
scale_y_continuous(limits = c(0,1)) +
geom_errorbar(aes(ymin=lower_tet, ymax=upper_tet),  size=0.5, width = 0) +
labs(title = "Tetracycline Usage in Fat Pigs: 2015-2019", x = "Tetracycline Usage", y = "Proportion Pigs Resistant")
# Comb Plots --------------------------------------------------------------
broilers <- ggarrange(broil_amp, broil_tet, ncol = 2, nrow = 1)
pigs <- ggarrange(pig_amp, pig_tet, ncol = 2, nrow = 1)
ggsave(broilers, filename = "broil_comb_stat.png", dpi = 300, type = "cairo", width = 14, height = 5, units = "in",
path = "//csce.datastore.ed.ac.uk/csce/biology/users/s1678248/PhD/Chapter_2/Figures/comb_data")
ggsave(pigs, filename = "pigs_comb_stat.png", dpi = 300, type = "cairo", width = 14, height = 5, units = "in",
path = "//csce.datastore.ed.ac.uk/csce/biology/users/s1678248/PhD/Chapter_2/Figures/comb_data")
library(reshape2); library(ggplot2); library(ggpubr); library(betareg)
>>>>>>> Stashed changes
rm(list=ls())
#Model
amr <- function(t, y, parms) {
with(as.list(c(y, parms)), {
dSa = ua + ra*(Isa + Ira) + kappa*tau*Isa - (betaAA*Isa*Sa) - (betaAH*Ish*Sa) - (1-alpha)*(betaAH*Irh*Sa) - (1-alpha)*(betaAA*Ira*Sa) - ua*Sa -
zeta*Sa*(1-alpha) - zeta*Sa
dIsa = betaAA*Isa*Sa + betaAH*Ish*Sa + phi*Ira - kappa*tau*Isa - tau*Isa - ra*Isa - ua*Isa + zeta*Sa
dIra = (1-alpha)*betaAH*Irh*Sa + (1-alpha)*betaAA*Ira*Sa + tau*Isa - phi*Ira - ra*Ira - ua*Ira + zeta*Sa*(1-alpha)
dSh = uh + rh*(Ish+Irh) - (betaHH*Ish*Sh) - (1-alpha)*(betaHH*Irh*Sh) - (betaHA*Isa*Sh) - (1-alpha)*(betaHA*Ira*Sh) - uh*Sh
dIsh = betaHH*Ish*Sh + betaHA*Isa*Sh - rh*Ish - uh*Ish
dIrh = (1-alpha)*(betaHH*Irh*Sh) + (1-alpha)*(betaHA*Ira*Sh) - rh*Irh - uh*Irh
CumS = betaHH*Ish*Sh + betaHA*Isa*Sh
CumR = (1-alpha)*(betaHH*Irh*Sh) + (1-alpha)*(betaHA*Ira*Sh)
return(list(c(dSa,dIsa,dIra,dSh,dIsh,dIrh), CumS, CumR))
})
}
init.state = c(Sa=0.98, Isa=0.01, Ira=0.01, Sh=1, Ish=0, Irh=0)
thetaparm <- c(ra = 60^-1, rh = (5.5^-1), ua = 240^-1, uh = 28835^-1, betaAA = 0.01, betaAH = 0.00001, betaHH = 0.00001,
betaHA = 0.01, phi = 0.01, kappa = 0.01, alpha = 0.01, zeta = 0.01, tau = 0.01)
outruns <- runsteady(y = init.state, func = amr, times = c(0, Inf), parms = thetaparm)
outdes <- ode(y = init.state, func = amr, times = seq(0, 1000), parms = thetaparm)
View(outruns)
View(outdes)
read.delim("C:/Users/amorg/Downloads/alex_ab_food_AmpBroil.52")
test <- read.delim("C:/Users/amorg/Downloads/alex_ab_food_AmpBroil.52")
library("deSolve"); library("ggplot2"); library("plotly"); library("reshape2")
library("bayestestR"); library("tmvtnorm"); library("ggpubr"); library("rootSolve")
rm(list=ls())
setwd("//csce.datastore.ed.ac.uk/csce/biology/users/s1678248/PhD/Chapter_2/Models/Chapter-2/NewFits_041021/data")
#Model
amr <- function(t, y, parms) {
with(as.list(c(y, parms)), {
dSa = ua + ra*(Isa + Ira) + kappa*tau*Isa - (betaAA*Isa*Sa) - (betaAH*Ish*Sa) - (1-alpha)*(betaAH*Irh*Sa) - (1-alpha)*(betaAA*Ira*Sa) - ua*Sa -
(0.5*zeta)*Sa*(1-alpha) - (0.5*zeta)*Sa
dIsa = betaAA*Isa*Sa + betaAH*Ish*Sa + phi*Ira - kappa*tau*Isa - tau*Isa - ra*Isa - ua*Isa + (0.5*zeta)*Sa
dIra = (1-alpha)*betaAH*Irh*Sa + (1-alpha)*betaAA*Ira*Sa + tau*Isa - phi*Ira - ra*Ira - ua*Ira + (0.5*zeta)*Sa*(1-alpha)
dSh = uh + rh*(Ish+Irh) - (betaHH*Ish*Sh) - (1-alpha)*(betaHH*Irh*Sh) - (betaHA*Isa*Sh) - (1-alpha)*(betaHA*Ira*Sh) - uh*Sh
dIsh = betaHH*Ish*Sh + betaHA*Isa*Sh - rh*Ish - uh*Ish
dIrh = (1-alpha)*(betaHH*Irh*Sh) + (1-alpha)*(betaHA*Ira*Sh) - rh*Irh - uh*Irh
CumS = betaHH*Ish*Sh + betaHA*Isa*Sh
CumR = (1-alpha)*(betaHH*Irh*Sh) + (1-alpha)*(betaHA*Ira*Sh)
return(list(c(dSa,dIsa,dIra,dSh,dIsh,dIrh), CumS, CumR))
})
}
#### Data Import ####
#Import Data
dataamp_broil <- read.csv("Amp_Broil_Comb.csv")
dataamp_hum <- read.csv("Hum_Broil.csv")
#Cleaning Data - Animals
dataamp_broil[,(2+4):(5+4)][dataamp_broil[,2:5] < 10] <- NA #If N > 10, replace the particular country/year with NA for the No. of pos isolates
dataamp_broil[,(2+8):(5+8)][dataamp_broil[,2:5] < 10] <- NA #If N > 10, replace the particular country/year with NA for the prop of resistant isolates
dataamp_broil[,2:5][dataamp_broil[,2:5] < 10] <- NA #If N > 10, replace the particular country/year with NA for N
dataamp_broil <- dataamp_broil[!(is.na(dataamp_broil$N_2014) & is.na(dataamp_broil$N_2016) & is.na(dataamp_broil$N_2017) &
is.na(dataamp_broil$N_2018)),]
broil_yrs <- sub("N_", "", grep("N_20",colnames(dataamp_broil), value = TRUE)) #Find years of the EFSA and ESVAC data in the dataset
# NON-AGGREGATED - AMP PIGS  -------------------------------------------------------------
colnames(dataamp_broil)[10:13] <- broil_yrs
#Create dataset where each row is a different observation.
melt_amp_broil <- melt(dataamp_broil, id.vars = "Country", measure.vars = broil_yrs)
melt_amp_broil$usage <- melt(dataamp_broil, id.vars = "Country", measure.vars = c("scale_ampusage_2014", "scale_ampusage_2016",
"scale_ampusage_2017", "scale_ampusage_2018"))[,3]
melt_amp_broil$N <- melt(dataamp_broil, id.vars = "Country", measure.vars = c("N_2014", "N_2016",
"N_2017", "N_2018"))[,3]
melt_amp_broil$IsolPos <- melt(dataamp_broil, id.vars = "Country", measure.vars = c("PosIsol_2014", "PosIsol_2016",
"PosIsol_2017", "PosIsol_2018"))[,3]
colnames(melt_amp_broil)[c(2,3)] <- c("Year", "Resistance")
#Cleaning Data - Humans
#only include countries/years which are present in the resistance dataset
dataamp_hum <- dataamp_hum[dataamp_hum$Country %in% intersect(dataamp_hum$Country, dataamp_broil$Country),]
colnames(dataamp_hum)[26:31] <- as.character(2014:2019)
dataamp_hum_melt <- melt(dataamp_hum, id.vars = "Country", measure.vars = broil_yrs)
colnames(dataamp_hum_melt)[c(2,3)] <- c("Year", "Resistance")
# Combine Human and Livestock Dataset -----------------------------------------------------------------
melt_amp_broil$ResPropHum <- dataamp_hum_melt[,3] #Obtain the melted human resistances
melt_amp_broil <- melt_amp_broil[!is.na(melt_amp_broil$Resistance),]
melt_amp_broil <- melt_amp_broil[!is.na(melt_amp_broil$usage),] # Remove all rows with NAs for usage and resistance
#Add 95% CIs for each datapoint
melt_amp_broil$lower_tet <- unlist(lapply(1:nrow(melt_amp_broil), function(i) prop.test(melt_amp_broil$IsolPos[i],melt_amp_broil$N[i])[[6]][[1]]))
melt_amp_broil$upper_tet <- unlist(lapply(1:nrow(melt_amp_broil), function(i) prop.test(melt_amp_broil$IsolPos[i],melt_amp_broil$N[i])[[6]][[2]]))
#Rename the columns
colnames(melt_amp_broil) <- c("Country", "Year", "ResPropAnim", "Usage", "N", "IsolPos", "ResPropHum", "Lower_Tet", "Upper_Tet")
melt_amp_broil$Usage <- melt_amp_broil$Usage/1000 #Change from mg/PCU to g/PCU
ggplot(melt_amp_broil, aes(x = Usage, y= ResPropAnim, color = Country)) + geom_point() +
scale_x_continuous(expand = c(0, 0)) + scale_y_continuous(expand = c(0, 0), limits = c(0,1)) +
labs(x ="Livestock Antibiotic Usage (g/PCU)", y = "Antibiotic-Resistant Livestock Carriage")
#Find the average EU antibiotic usage and average human resistance for model fitting
avg_EU_usage <- mean(melt_amp_broil$Usage)
avg_hum_res <- mean(melt_amp_broil$ResPropHum, na.rm = TRUE)
#### Approximate Bayesian Computation - Rejection Algorithm ####
#Obtain the Resistance
summarystatprev <- function(prev) {
return(prev$ResPropAnim)
}
#Return the sum of squares between resistance and the model output
sum_square_diff_dist <- function(sum.stats, data.obs, model.obs) {
sumsquare <- sapply(sum.stats, function(x) {
sumsquare <- (x(data.obs) - x(model.obs))^2
})
return(sum(sumsquare))
}
#Compute the distances for all 3 summary statistics - this section involves running the model
computeDistanceABC_ALEX <- function(sum.stats, distanceABC, fitmodel, tau_range, thetaparm, init.state, data) {
tauoutput <-data.frame(matrix(nrow = length(tau_range), ncol=4))
tau_range <- append(tau_range, avg_EU_usage)
for (i in 1:length(tau_range)) {
parms2 = thetaparm
parms2["tau"] = tau_range[i]
out <- runsteady(y = init.state, func = fitmodel, times = c(0, Inf), parms = parms2)
tauoutput[i,] <- c(tau_range[i],
((out[[2]] + out[[3]])*(446000000))/100000,
out[[1]][["Ira"]] / (out[[1]][["Isa"]] + out[[1]][["Ira"]]),
out[[1]][["Irh"]] / (out[[1]][["Ish"]] + out[[1]][["Irh"]]))
}
tauoutput <- data.frame(tauoutput)
colnames(tauoutput) <- c("tau", "IncH", "ResPropAnim", "ResPropHum")
return(c(distanceABC(list(sum.stats), data, tauoutput[!tauoutput$tau == avg_EU_usage,]),
abs(tauoutput$IncH[tauoutput$tau == avg_EU_usage] - 0.593),
abs(tauoutput$ResPropHum[tauoutput$tau == avg_EU_usage] - avg_hum_res)))
}
library("deSolve"); library("ggplot2"); library("plotly"); library("reshape2")
library("bayestestR"); library("tmvtnorm"); library("ggpubr"); library("rootSolve")
rm(list=ls())
setwd("C:/Users/amorg/Documents/PhD/Chapter_2/Models/Github/Chapter-2/NewFits_041021/data")
#Model
amr <- function(t, y, parms) {
with(as.list(c(y, parms)), {
dSa = ua + ra*(Isa + Ira) + kappa*tau*Isa - (betaAA*Isa*Sa) - (betaAH*Ish*Sa) - (1-alpha)*(betaAH*Irh*Sa) - (1-alpha)*(betaAA*Ira*Sa) - ua*Sa -
(0.5*zeta)*Sa*(1-alpha) - (0.5*zeta)*Sa
dIsa = betaAA*Isa*Sa + betaAH*Ish*Sa + phi*Ira - kappa*tau*Isa - tau*Isa - ra*Isa - ua*Isa + (0.5*zeta)*Sa
dIra = (1-alpha)*betaAH*Irh*Sa + (1-alpha)*betaAA*Ira*Sa + tau*Isa - phi*Ira - ra*Ira - ua*Ira + (0.5*zeta)*Sa*(1-alpha)
dSh = uh + rh*(Ish+Irh) - (betaHH*Ish*Sh) - (1-alpha)*(betaHH*Irh*Sh) - (betaHA*Isa*Sh) - (1-alpha)*(betaHA*Ira*Sh) - uh*Sh
dIsh = betaHH*Ish*Sh + betaHA*Isa*Sh - rh*Ish - uh*Ish
dIrh = (1-alpha)*(betaHH*Irh*Sh) + (1-alpha)*(betaHA*Ira*Sh) - rh*Irh - uh*Irh
CumS = betaHH*Ish*Sh + betaHA*Isa*Sh
CumR = (1-alpha)*(betaHH*Irh*Sh) + (1-alpha)*(betaHA*Ira*Sh)
return(list(c(dSa,dIsa,dIra,dSh,dIsh,dIrh), CumS, CumR))
})
}
#### Data Import ####
#Import Data
dataamp_broil <- read.csv("Amp_Broil_Comb.csv")
dataamp_hum <- read.csv("Hum_Broil.csv")
#Cleaning Data - Animals
dataamp_broil[,(2+4):(5+4)][dataamp_broil[,2:5] < 10] <- NA #If N > 10, replace the particular country/year with NA for the No. of pos isolates
dataamp_broil[,(2+8):(5+8)][dataamp_broil[,2:5] < 10] <- NA #If N > 10, replace the particular country/year with NA for the prop of resistant isolates
dataamp_broil[,2:5][dataamp_broil[,2:5] < 10] <- NA #If N > 10, replace the particular country/year with NA for N
dataamp_broil <- dataamp_broil[!(is.na(dataamp_broil$N_2014) & is.na(dataamp_broil$N_2016) & is.na(dataamp_broil$N_2017) &
is.na(dataamp_broil$N_2018)),]
broil_yrs <- sub("N_", "", grep("N_20",colnames(dataamp_broil), value = TRUE)) #Find years of the EFSA and ESVAC data in the dataset
# NON-AGGREGATED - AMP PIGS  -------------------------------------------------------------
colnames(dataamp_broil)[10:13] <- broil_yrs
#Create dataset where each row is a different observation.
melt_amp_broil <- melt(dataamp_broil, id.vars = "Country", measure.vars = broil_yrs)
melt_amp_broil$usage <- melt(dataamp_broil, id.vars = "Country", measure.vars = c("scale_ampusage_2014", "scale_ampusage_2016",
"scale_ampusage_2017", "scale_ampusage_2018"))[,3]
melt_amp_broil$N <- melt(dataamp_broil, id.vars = "Country", measure.vars = c("N_2014", "N_2016",
"N_2017", "N_2018"))[,3]
melt_amp_broil$IsolPos <- melt(dataamp_broil, id.vars = "Country", measure.vars = c("PosIsol_2014", "PosIsol_2016",
"PosIsol_2017", "PosIsol_2018"))[,3]
colnames(melt_amp_broil)[c(2,3)] <- c("Year", "Resistance")
#Cleaning Data - Humans
#only include countries/years which are present in the resistance dataset
dataamp_hum <- dataamp_hum[dataamp_hum$Country %in% intersect(dataamp_hum$Country, dataamp_broil$Country),]
colnames(dataamp_hum)[26:31] <- as.character(2014:2019)
dataamp_hum_melt <- melt(dataamp_hum, id.vars = "Country", measure.vars = broil_yrs)
colnames(dataamp_hum_melt)[c(2,3)] <- c("Year", "Resistance")
# Combine Human and Livestock Dataset -----------------------------------------------------------------
melt_amp_broil$ResPropHum <- dataamp_hum_melt[,3] #Obtain the melted human resistances
melt_amp_broil <- melt_amp_broil[!is.na(melt_amp_broil$Resistance),]
melt_amp_broil <- melt_amp_broil[!is.na(melt_amp_broil$usage),] # Remove all rows with NAs for usage and resistance
#Add 95% CIs for each datapoint
melt_amp_broil$lower_tet <- unlist(lapply(1:nrow(melt_amp_broil), function(i) prop.test(melt_amp_broil$IsolPos[i],melt_amp_broil$N[i])[[6]][[1]]))
melt_amp_broil$upper_tet <- unlist(lapply(1:nrow(melt_amp_broil), function(i) prop.test(melt_amp_broil$IsolPos[i],melt_amp_broil$N[i])[[6]][[2]]))
#Rename the columns
colnames(melt_amp_broil) <- c("Country", "Year", "ResPropAnim", "Usage", "N", "IsolPos", "ResPropHum", "Lower_Tet", "Upper_Tet")
melt_amp_broil$Usage <- melt_amp_broil$Usage/1000 #Change from mg/PCU to g/PCU
ggplot(melt_amp_broil, aes(x = Usage, y= ResPropAnim, color = Country)) + geom_point() +
scale_x_continuous(expand = c(0, 0)) + scale_y_continuous(expand = c(0, 0), limits = c(0,1)) +
labs(x ="Livestock Antibiotic Usage (g/PCU)", y = "Antibiotic-Resistant Livestock Carriage")
#Find the average EU antibiotic usage and average human resistance for model fitting
avg_EU_usage <- mean(melt_amp_broil$Usage)
avg_hum_res <- mean(melt_amp_broil$ResPropHum, na.rm = TRUE)
#### Approximate Bayesian Computation - Rejection Algorithm ####
#Obtain the Resistance
summarystatprev <- function(prev) {
return(prev$ResPropAnim)
}
#Return the sum of squares between resistance and the model output
sum_square_diff_dist <- function(sum.stats, data.obs, model.obs) {
sumsquare <- sapply(sum.stats, function(x) {
sumsquare <- (x(data.obs) - x(model.obs))^2
})
return(sum(sumsquare))
}
#Compute the distances for all 3 summary statistics - this section involves running the model
computeDistanceABC_ALEX <- function(sum.stats, distanceABC, fitmodel, tau_range, thetaparm, init.state, data) {
tauoutput <-data.frame(matrix(nrow = length(tau_range), ncol=4))
tau_range <- append(tau_range, avg_EU_usage)
for (i in 1:length(tau_range)) {
parms2 = thetaparm
parms2["tau"] = tau_range[i]
out <- runsteady(y = init.state, func = fitmodel, times = c(0, Inf), parms = parms2)
tauoutput[i,] <- c(tau_range[i],
((out[[2]] + out[[3]])*(446000000))/100000,
out[[1]][["Ira"]] / (out[[1]][["Isa"]] + out[[1]][["Ira"]]),
out[[1]][["Irh"]] / (out[[1]][["Ish"]] + out[[1]][["Irh"]]))
}
tauoutput <- data.frame(tauoutput)
colnames(tauoutput) <- c("tau", "IncH", "ResPropAnim", "ResPropHum")
return(c(distanceABC(list(sum.stats), data, tauoutput[!tauoutput$tau == avg_EU_usage,]),
abs(tauoutput$IncH[tauoutput$tau == avg_EU_usage] - 0.593),
abs(tauoutput$ResPropHum[tauoutput$tau == avg_EU_usage] - avg_hum_res)))
}
# Test --------------------------------------------------------------------
test <- read.delim("C:/Users/amorg/Downloads/alex_ab_food_AmpBroil.52")
map_estimate
map_estimate(test)
test
test <- read.delim("C:/Users/amorg/Downloads/alex_ab_food_AmpBroil.52")[3:8,]
map_estimate(test)
test
test <- read.delim("C:/Users/amorg/Downloads/alex_ab_food_AmpBroil.52")[,3:8]
map_estimate(test)
MAP$MAP_Estimate[MAP$Parameter = "kappa"]
MAP$MAP_Estimate[MAP$Parameter == "kappa"]
test <- read.delim("C:/Users/amorg/Downloads/alex_ab_food_AmpBroil.52")[,3:8]
MAP <- map_estimate(test)
MAP$MAP_Estimate[MAP$Parameter == "kappa"]
library("deSolve"); library("ggplot2"); library("plotly"); library("reshape2")
library("bayestestR"); library("tmvtnorm"); library("ggpubr"); library("rootSolve")
rm(list=ls())
setwd("C:/Users/amorg/Documents/PhD/Chapter_2/Models/Github/Chapter-2/NewFits_041021/data")
#Model
amr <- function(t, y, parms) {
with(as.list(c(y, parms)), {
dSa = ua + ra*(Isa + Ira) + kappa*tau*Isa - (betaAA*Isa*Sa) - (betaAH*Ish*Sa) - (1-alpha)*(betaAH*Irh*Sa) - (1-alpha)*(betaAA*Ira*Sa) - ua*Sa -
(0.5*zeta)*Sa*(1-alpha) - (0.5*zeta)*Sa
dIsa = betaAA*Isa*Sa + betaAH*Ish*Sa + phi*Ira - kappa*tau*Isa - tau*Isa - ra*Isa - ua*Isa + (0.5*zeta)*Sa
dIra = (1-alpha)*betaAH*Irh*Sa + (1-alpha)*betaAA*Ira*Sa + tau*Isa - phi*Ira - ra*Ira - ua*Ira + (0.5*zeta)*Sa*(1-alpha)
dSh = uh + rh*(Ish+Irh) - (betaHH*Ish*Sh) - (1-alpha)*(betaHH*Irh*Sh) - (betaHA*Isa*Sh) - (1-alpha)*(betaHA*Ira*Sh) - uh*Sh
dIsh = betaHH*Ish*Sh + betaHA*Isa*Sh - rh*Ish - uh*Ish
dIrh = (1-alpha)*(betaHH*Irh*Sh) + (1-alpha)*(betaHA*Ira*Sh) - rh*Irh - uh*Irh
CumS = betaHH*Ish*Sh + betaHA*Isa*Sh
CumR = (1-alpha)*(betaHH*Irh*Sh) + (1-alpha)*(betaHA*Ira*Sh)
return(list(c(dSa,dIsa,dIra,dSh,dIsh,dIrh), CumS, CumR))
})
}
#### Data Import ####
#Import Data
dataamp_broil <- read.csv("Amp_Broil_Comb.csv")
dataamp_hum <- read.csv("Hum_Broil.csv")
#Cleaning Data - Animals
dataamp_broil[,(2+4):(5+4)][dataamp_broil[,2:5] < 10] <- NA #If N > 10, replace the particular country/year with NA for the No. of pos isolates
dataamp_broil[,(2+8):(5+8)][dataamp_broil[,2:5] < 10] <- NA #If N > 10, replace the particular country/year with NA for the prop of resistant isolates
dataamp_broil[,2:5][dataamp_broil[,2:5] < 10] <- NA #If N > 10, replace the particular country/year with NA for N
dataamp_broil <- dataamp_broil[!(is.na(dataamp_broil$N_2014) & is.na(dataamp_broil$N_2016) & is.na(dataamp_broil$N_2017) &
is.na(dataamp_broil$N_2018)),]
broil_yrs <- sub("N_", "", grep("N_20",colnames(dataamp_broil), value = TRUE)) #Find years of the EFSA and ESVAC data in the dataset
# NON-AGGREGATED - AMP PIGS  -------------------------------------------------------------
colnames(dataamp_broil)[10:13] <- broil_yrs
#Create dataset where each row is a different observation.
melt_amp_broil <- melt(dataamp_broil, id.vars = "Country", measure.vars = broil_yrs)
melt_amp_broil$usage <- melt(dataamp_broil, id.vars = "Country", measure.vars = c("scale_ampusage_2014", "scale_ampusage_2016",
"scale_ampusage_2017", "scale_ampusage_2018"))[,3]
melt_amp_broil$N <- melt(dataamp_broil, id.vars = "Country", measure.vars = c("N_2014", "N_2016",
"N_2017", "N_2018"))[,3]
melt_amp_broil$IsolPos <- melt(dataamp_broil, id.vars = "Country", measure.vars = c("PosIsol_2014", "PosIsol_2016",
"PosIsol_2017", "PosIsol_2018"))[,3]
colnames(melt_amp_broil)[c(2,3)] <- c("Year", "Resistance")
#Cleaning Data - Humans
#only include countries/years which are present in the resistance dataset
dataamp_hum <- dataamp_hum[dataamp_hum$Country %in% intersect(dataamp_hum$Country, dataamp_broil$Country),]
colnames(dataamp_hum)[26:31] <- as.character(2014:2019)
dataamp_hum_melt <- melt(dataamp_hum, id.vars = "Country", measure.vars = broil_yrs)
colnames(dataamp_hum_melt)[c(2,3)] <- c("Year", "Resistance")
# Combine Human and Livestock Dataset -----------------------------------------------------------------
melt_amp_broil$ResPropHum <- dataamp_hum_melt[,3] #Obtain the melted human resistances
melt_amp_broil <- melt_amp_broil[!is.na(melt_amp_broil$Resistance),]
melt_amp_broil <- melt_amp_broil[!is.na(melt_amp_broil$usage),] # Remove all rows with NAs for usage and resistance
#Add 95% CIs for each datapoint
melt_amp_broil$lower_tet <- unlist(lapply(1:nrow(melt_amp_broil), function(i) prop.test(melt_amp_broil$IsolPos[i],melt_amp_broil$N[i])[[6]][[1]]))
melt_amp_broil$upper_tet <- unlist(lapply(1:nrow(melt_amp_broil), function(i) prop.test(melt_amp_broil$IsolPos[i],melt_amp_broil$N[i])[[6]][[2]]))
#Rename the columns
colnames(melt_amp_broil) <- c("Country", "Year", "ResPropAnim", "Usage", "N", "IsolPos", "ResPropHum", "Lower_Tet", "Upper_Tet")
melt_amp_broil$Usage <- melt_amp_broil$Usage/1000 #Change from mg/PCU to g/PCU
ggplot(melt_amp_broil, aes(x = Usage, y= ResPropAnim, color = Country)) + geom_point() +
scale_x_continuous(expand = c(0, 0)) + scale_y_continuous(expand = c(0, 0), limits = c(0,1)) +
labs(x ="Livestock Antibiotic Usage (g/PCU)", y = "Antibiotic-Resistant Livestock Carriage")
#Find the average EU antibiotic usage and average human resistance for model fitting
avg_EU_usage <- mean(melt_amp_broil$Usage)
avg_hum_res <- mean(melt_amp_broil$ResPropHum, na.rm = TRUE)
#### Approximate Bayesian Computation - Rejection Algorithm ####
#Obtain the Resistance
summarystatprev <- function(prev) {
return(prev$ResPropAnim)
}
#Return the sum of squares between resistance and the model output
sum_square_diff_dist <- function(sum.stats, data.obs, model.obs) {
sumsquare <- sapply(sum.stats, function(x) {
sumsquare <- (x(data.obs) - x(model.obs))^2
})
return(sum(sumsquare))
}
#Compute the distances for all 3 summary statistics - this section involves running the model
computeDistanceABC_ALEX <- function(sum.stats, distanceABC, fitmodel, tau_range, thetaparm, init.state, data) {
tauoutput <-data.frame(matrix(nrow = length(tau_range), ncol=4))
tau_range <- append(tau_range, avg_EU_usage)
for (i in 1:length(tau_range)) {
parms2 = thetaparm
parms2["tau"] = tau_range[i]
out <- runsteady(y = init.state, func = fitmodel, times = c(0, Inf), parms = parms2)
tauoutput[i,] <- c(tau_range[i],
((out[[2]] + out[[3]])*(446000000))/100000,
out[[1]][["Ira"]] / (out[[1]][["Isa"]] + out[[1]][["Ira"]]),
out[[1]][["Irh"]] / (out[[1]][["Ish"]] + out[[1]][["Irh"]]))
}
tauoutput <- data.frame(tauoutput)
colnames(tauoutput) <- c("tau", "IncH", "ResPropAnim", "ResPropHum")
return(c(distanceABC(list(sum.stats), data, tauoutput[!tauoutput$tau == avg_EU_usage,]),
abs(tauoutput$IncH[tauoutput$tau == avg_EU_usage] - 0.593),
abs(tauoutput$ResPropHum[tauoutput$tau == avg_EU_usage] - avg_hum_res)))
}
<<<<<<< Updated upstream
# Test --------------------------------------------------------------------
test <- read.delim("C:/Users/amorg/Downloads/alex_ab_food_AmpBroil.52")[,3:8]
MAP <- map_estimate(test)
MAP$MAP_Estimate[MAP$Parameter == "kappa"]
computeDistanceABC_ALEX(sum.stats = list(summarystatprev),
distanceABC = sum_square_diff_dist,
fitmodel = amr,
tau_range = melt_amp_broil$Usage,
thetaparm = c(ra = 0, rh = (5.5^-1), ua = 42^-1, uh = 28835^-1, betaAA = MAP$MAP_Estimate[MAP$Parameter == "betaAA"], betaAH = 0.00001, betaHH = 0.00001,
betaHA = MAP$MAP_Estimate[MAP$Parameter == "betaHA"], phi = MAP$MAP_Estimate[MAP$Parameter == "phi"], kappa = MAP$MAP_Estimate[MAP$Parameter == "kappa"],
alpha = MAP$MAP_Estimate[MAP$Parameter == "alpha"], zeta = MAP$MAP_Estimate[MAP$Parameter == "zeta"]),
init.state =c(Sa=0.98, Isa=0.01, Ira=0.01, Sh=1, Ish=0, Irh=0),
data = melt_amp_broil)
library("deSolve"); library("ggplot2"); library("plotly"); library("reshape2")
library("bayestestR"); library("tmvtnorm"); library("ggpubr"); library("rootSolve")
rm(list=ls())
setwd("C:/Users/amorg/Documents/PhD/Chapter_2/Models/Github/Chapter-2/NewFits_041021/data")
#Model
amr <- function(t, y, parms) {
with(as.list(c(y, parms)), {
dSa = ua + ra*(Isa + Ira) + kappa*tau*Isa - (betaAA*Isa*Sa) - (betaAH*Ish*Sa) - (1-alpha)*(betaAH*Irh*Sa) - (1-alpha)*(betaAA*Ira*Sa) - ua*Sa -
(0.5*zeta)*Sa*(1-alpha) - (0.5*zeta)*Sa
dIsa = betaAA*Isa*Sa + betaAH*Ish*Sa + phi*Ira - kappa*tau*Isa - tau*Isa - ra*Isa - ua*Isa + (0.5*zeta)*Sa
dIra = (1-alpha)*betaAH*Irh*Sa + (1-alpha)*betaAA*Ira*Sa + tau*Isa - phi*Ira - ra*Ira - ua*Ira + (0.5*zeta)*Sa*(1-alpha)
dSh = uh + rh*(Ish+Irh) - (betaHH*Ish*Sh) - (1-alpha)*(betaHH*Irh*Sh) - (betaHA*Isa*Sh) - (1-alpha)*(betaHA*Ira*Sh) - uh*Sh
dIsh = betaHH*Ish*Sh + betaHA*Isa*Sh - rh*Ish - uh*Ish
dIrh = (1-alpha)*(betaHH*Irh*Sh) + (1-alpha)*(betaHA*Ira*Sh) - rh*Irh - uh*Irh
CumS = betaHH*Ish*Sh + betaHA*Isa*Sh
CumR = (1-alpha)*(betaHH*Irh*Sh) + (1-alpha)*(betaHA*Ira*Sh)
return(list(c(dSa,dIsa,dIra,dSh,dIsh,dIrh), CumS, CumR))
})
}
#### Data Import ####
#Import Data
dataamp_broil <- read.csv("Amp_Broil_Comb.csv")
dataamp_hum <- read.csv("Hum_Broil.csv")
#Cleaning Data - Animals
dataamp_broil[,(2+4):(5+4)][dataamp_broil[,2:5] < 10] <- NA #If N > 10, replace the particular country/year with NA for the No. of pos isolates
dataamp_broil[,(2+8):(5+8)][dataamp_broil[,2:5] < 10] <- NA #If N > 10, replace the particular country/year with NA for the prop of resistant isolates
dataamp_broil[,2:5][dataamp_broil[,2:5] < 10] <- NA #If N > 10, replace the particular country/year with NA for N
dataamp_broil <- dataamp_broil[!(is.na(dataamp_broil$N_2014) & is.na(dataamp_broil$N_2016) & is.na(dataamp_broil$N_2017) &
is.na(dataamp_broil$N_2018)),]
broil_yrs <- sub("N_", "", grep("N_20",colnames(dataamp_broil), value = TRUE)) #Find years of the EFSA and ESVAC data in the dataset
# NON-AGGREGATED - AMP PIGS  -------------------------------------------------------------
colnames(dataamp_broil)[10:13] <- broil_yrs
#Create dataset where each row is a different observation.
melt_amp_broil <- melt(dataamp_broil, id.vars = "Country", measure.vars = broil_yrs)
melt_amp_broil$usage <- melt(dataamp_broil, id.vars = "Country", measure.vars = c("scale_ampusage_2014", "scale_ampusage_2016",
"scale_ampusage_2017", "scale_ampusage_2018"))[,3]
melt_amp_broil$N <- melt(dataamp_broil, id.vars = "Country", measure.vars = c("N_2014", "N_2016",
"N_2017", "N_2018"))[,3]
melt_amp_broil$IsolPos <- melt(dataamp_broil, id.vars = "Country", measure.vars = c("PosIsol_2014", "PosIsol_2016",
"PosIsol_2017", "PosIsol_2018"))[,3]
colnames(melt_amp_broil)[c(2,3)] <- c("Year", "Resistance")
#Cleaning Data - Humans
#only include countries/years which are present in the resistance dataset
dataamp_hum <- dataamp_hum[dataamp_hum$Country %in% intersect(dataamp_hum$Country, dataamp_broil$Country),]
colnames(dataamp_hum)[26:31] <- as.character(2014:2019)
dataamp_hum_melt <- melt(dataamp_hum, id.vars = "Country", measure.vars = broil_yrs)
colnames(dataamp_hum_melt)[c(2,3)] <- c("Year", "Resistance")
# Combine Human and Livestock Dataset -----------------------------------------------------------------
melt_amp_broil$ResPropHum <- dataamp_hum_melt[,3] #Obtain the melted human resistances
melt_amp_broil <- melt_amp_broil[!is.na(melt_amp_broil$Resistance),]
melt_amp_broil <- melt_amp_broil[!is.na(melt_amp_broil$usage),] # Remove all rows with NAs for usage and resistance
#Add 95% CIs for each datapoint
melt_amp_broil$lower_tet <- unlist(lapply(1:nrow(melt_amp_broil), function(i) prop.test(melt_amp_broil$IsolPos[i],melt_amp_broil$N[i])[[6]][[1]]))
melt_amp_broil$upper_tet <- unlist(lapply(1:nrow(melt_amp_broil), function(i) prop.test(melt_amp_broil$IsolPos[i],melt_amp_broil$N[i])[[6]][[2]]))
#Rename the columns
colnames(melt_amp_broil) <- c("Country", "Year", "ResPropAnim", "Usage", "N", "IsolPos", "ResPropHum", "Lower_Tet", "Upper_Tet")
melt_amp_broil$Usage <- melt_amp_broil$Usage/1000 #Change from mg/PCU to g/PCU
ggplot(melt_amp_broil, aes(x = Usage, y= ResPropAnim, color = Country)) + geom_point() +
scale_x_continuous(expand = c(0, 0)) + scale_y_continuous(expand = c(0, 0), limits = c(0,1)) +
labs(x ="Livestock Antibiotic Usage (g/PCU)", y = "Antibiotic-Resistant Livestock Carriage")
#Find the average EU antibiotic usage and average human resistance for model fitting
avg_EU_usage <- mean(melt_amp_broil$Usage)
avg_hum_res <- mean(melt_amp_broil$ResPropHum, na.rm = TRUE)
#### Approximate Bayesian Computation - Rejection Algorithm ####
#Obtain the Resistance
summarystatprev <- function(prev) {
return(prev$ResPropAnim)
}
#Return the sum of squares between resistance and the model output
sum_square_diff_dist <- function(sum.stats, data.obs, model.obs) {
sumsquare <- sapply(sum.stats, function(x) {
sumsquare <- (x(data.obs) - x(model.obs))^2
})
return(sum(sumsquare))
}
#Compute the distances for all 3 summary statistics - this section involves running the model
computeDistanceABC_ALEX <- function(sum.stats, distanceABC, fitmodel, tau_range, thetaparm, init.state, data) {
tauoutput <-data.frame(matrix(nrow = length(tau_range), ncol=4))
tau_range <- append(tau_range, avg_EU_usage)
for (i in 1:length(tau_range)) {
parms2 = thetaparm
parms2["tau"] = tau_range[i]
out <- runsteady(y = init.state, func = fitmodel, times = c(0, Inf), parms = parms2)
tauoutput[i,] <- c(tau_range[i],
((out[[2]] + out[[3]])*(446000000))/100000,
out[[1]][["Ira"]] / (out[[1]][["Isa"]] + out[[1]][["Ira"]]),
out[[1]][["Irh"]] / (out[[1]][["Ish"]] + out[[1]][["Irh"]]))
}
tauoutput <- data.frame(tauoutput)
colnames(tauoutput) <- c("tau", "IncH", "ResPropAnim", "ResPropHum")
return(c(distanceABC(list(sum.stats), data, tauoutput[!tauoutput$tau == avg_EU_usage,]),
abs(tauoutput$IncH[tauoutput$tau == avg_EU_usage] - 0.593),
abs(tauoutput$ResPropHum[tauoutput$tau == avg_EU_usage] - avg_hum_res)))
}
# Test --------------------------------------------------------------------
test <- read.delim("C:/Users/amorg/Downloads/alex_ab_food_AmpBroil.52")[,3:8]
MAP <- map_estimate(test)
MAP$MAP_Estimate[MAP$Parameter == "kappa"]
computeDistanceABC_ALEX(sum.stats = summarystatprev,
distanceABC = sum_square_diff_dist,
fitmodel = amr,
tau_range = melt_amp_broil$Usage,
thetaparm = c(ra = 0, rh = (5.5^-1), ua = 42^-1, uh = 28835^-1, betaAA = MAP$MAP_Estimate[MAP$Parameter == "betaAA"], betaAH = 0.00001, betaHH = 0.00001,
betaHA = MAP$MAP_Estimate[MAP$Parameter == "betaHA"], phi = MAP$MAP_Estimate[MAP$Parameter == "phi"], kappa = MAP$MAP_Estimate[MAP$Parameter == "kappa"],
alpha = MAP$MAP_Estimate[MAP$Parameter == "alpha"], zeta = MAP$MAP_Estimate[MAP$Parameter == "zeta"]),
init.state =c(Sa=0.98, Isa=0.01, Ira=0.01, Sh=1, Ish=0, Irh=0),
data = melt_amp_broil)
tau_range <- melt_amp_broil$Usage
tauoutput <- data.frame(matrix(nrow = length(tau_range), ncol=4))
init.state = c(Sa=0.98, Isa=0.01, Ira=0.01, Sh=1, Ish=0, Irh=0)
for (i in 1:length(tau_range)) {
parms2 =  c(ra = 0, rh = (5.5^-1), ua = 42^-1, uh = 28835^-1,
betaAA = test_MAP$MAP_Estimate[test_MAP$Parameter == "betaAA"],
betaAH = 0.00001, betaHH = 0.00001,
betaHA = test_MAP$MAP_Estimate[test_MAP$Parameter == "betaHA"],
phi = test_MAP$MAP_Estimate[test_MAP$Parameter == "phi"],
kappa = test_MAP$MAP_Estimate[test_MAP$Parameter == "kappa"],
alpha = test_MAP$MAP_Estimate[test_MAP$Parameter == "alpha"],
zeta = test_MAP$MAP_Estimate[test_MAP$Parameter == "zeta"])
parms2["tau"] = tau_range[i]
out <- runsteady(y = init.state, func = amr, times = c(0, Inf),
parms = parms2)
tauoutput[i,] <- c(tau_range[i],
((out[[2]] + out[[3]])*(446000000))/100000,
out[[1]][["Ira"]] / (out[[1]][["Isa"]] + out[[1]][["Ira"]]),
out[[1]][["Irh"]] / (out[[1]][["Ish"]] + out[[1]][["Irh"]]))
}
tauoutput <- data.frame(tauoutput)
colnames(tauoutput) <- c("tau", "IncH", "ResPropAnim", "ResPropHum")
test_MAP <- map_estimate(test)
tau_range <- melt_amp_broil$Usage
tauoutput <- data.frame(matrix(nrow = length(tau_range), ncol=4))
init.state = c(Sa=0.98, Isa=0.01, Ira=0.01, Sh=1, Ish=0, Irh=0)
for (i in 1:length(tau_range)) {
parms2 =  c(ra = 0, rh = (5.5^-1), ua = 42^-1, uh = 28835^-1,
betaAA = test_MAP$MAP_Estimate[test_MAP$Parameter == "betaAA"],
betaAH = 0.00001, betaHH = 0.00001,
betaHA = test_MAP$MAP_Estimate[test_MAP$Parameter == "betaHA"],
phi = test_MAP$MAP_Estimate[test_MAP$Parameter == "phi"],
kappa = test_MAP$MAP_Estimate[test_MAP$Parameter == "kappa"],
alpha = test_MAP$MAP_Estimate[test_MAP$Parameter == "alpha"],
zeta = test_MAP$MAP_Estimate[test_MAP$Parameter == "zeta"])
parms2["tau"] = tau_range[i]
out <- runsteady(y = init.state, func = amr, times = c(0, Inf),
parms = parms2)
=======
#Where G is the number of generations
#Function to 100% make sure the sampled particles for all parameters are non zero
prior.non.zero<-function(par){
prod(sapply(1:6, function(a) as.numeric((par[a]-lm.low[a]) > 0) * as.numeric((lm.upp[a]-par[a]) > 0)))
}
#Wrapper function for all of the functions to output the distance measures and the diagnostics
#Saving of the accepted particles in each generation done within the function
ABC_algorithm <- function(N, G, sum.stats, distanceABC, fitmodel, tau_range, init.state, data)  {
N_ITER_list <- list()
fit_parms <- c("betaAA", "phi", "kappa", "alpha", "zeta", "betaHA")
thetaparm <- c(ra = 0, rh = (5.5^-1), ua = 42^-1, uh = 28835^-1, betaAH = 0.00001, betaHH = 0.00001)
for(g in 1:G) {
i <- 1
dist_data <- data.frame(matrix(nrow = 1000, ncol = 3))
N_ITER <- 1
while(i <= N) {
N_ITER <- N_ITER + 1
if(g==1) {
d_betaAA <- runif(1, min = 0, max = 0.25)
d_phi <- runif(1, min = 0, max = 0.1)
d_kappa <- runif(1, min = 0, max = 2)
d_alpha <- rbeta(1, 1.5, 8.5)
d_zeta <- runif(1, 0, 1.5)
d_betaHA <- runif(1, 0, 0.0005)
} else{
p <- sample(seq(1,N),1,prob= w.old) # check w.old here
par <- rtmvnorm(1, mean=res.old[p,], sigma=sigma, lower=lm.low, upper=lm.upp)
d_betaAA<-par[1]
d_phi<-par[2]
d_kappa<-par[3]
d_alpha<-par[4]
d_zeta <- par[5]
d_betaHA <-par[6]
}
if(prior.non.zero(c(d_betaAA, d_phi, d_kappa, d_alpha, d_zeta, d_betaHA))) {
m <- 0
thetaparm <- c(ra = 0, rh = (5.5^-1), ua = 42^-1, uh = 28835^-1, betaAA = d_betaAA, betaAH = 0.00001, betaHH = 0.00001,
betaHA = d_betaHA, phi = d_phi, kappa = d_kappa, alpha = d_alpha, zeta = d_zeta)
dist <- computeDistanceABC_ALEX(sum.stats, distanceABC, fitmodel, tau_range, thetaparm, init.state, data)
print(dist)
if((dist[1] <= epsilon_dist[g]) && (dist[2] <= epsilon_food[g]) && (dist[3] <= epsilon_AMR[g]) && (!is.na(dist))) {
# Store results
res.new[i,]<-c(d_betaAA, d_phi, d_kappa, d_alpha, d_zeta, d_betaHA)
dist_data[i,] <- dist
# Calculate weights
if(g==1){
w.new[i] <- 1
} else {
w1<-prod(c(sapply(c(1:3,5:6), function(b) dunif(res.new[i,b], min=lm.low[b], max=lm.upp[b])),
dbeta(res.new[i,4], 1.5, 8.5)))
w2<-sum(sapply(1:N, function(a) w.old[a]* dtmvnorm(res.new[i,], mean=res.old[a,], sigma=sigma, lower=lm.low, upper=lm.upp)))
w.new[i] <- w1/w2
}
# Update counter
print(paste0('Generation: ', g, ", particle: ", i,", weights: ", w.new[i]))
print(dist)
i <- i+1
}
}
}
N_ITER_list[[g]] <- list(N_ITER, dist_data)
sigma <- cov(res.new)
res.old <- res.new
print(res.old)
w.old <- w.new/sum(w.new)
colnames(res.new) <- c("betaAA", "phi", "kappa", "alpha", "zeta", "betaHA")
write.csv(res.new, file = paste("//csce.datastore.ed.ac.uk/csce/biology/users/s1678248/PhD/Chapter_2/Models/Chapter-2/NewFits_041021/data/new/full/ABC_post_ampbroil_",g,".csv",sep=""), row.names=FALSE)
}
return(N_ITER_list)
}
N <- 1000 #(ACCEPTED PARTICLES PER GENERATION)
lm.low <- c(0, 0, 0, 0, 0, 0)
lm.upp <- c(0.25, 0.1, 2, 1, 1.5, 0.0005) #Upper and lower bounds for the priors - for the multivariate normal dist pert kernel
# Empty matrices to store results (6 model parameters)
res.old<-matrix(ncol=6,nrow=N)
res.new<-matrix(ncol=6,nrow=N)
# Empty vectors to store weights
w.old<-matrix(ncol=1,nrow=N)
w.new<-matrix(ncol=1,nrow=N)
#Thresholds
epsilon_dist <-  c(5, 4, 3.5, 3.25, 3, 2.75, 2.5, 2.25, 2.1, 2)
epsilon_food <- c(0.593*1, 0.593*0.8, 0.593*0.6, 0.593*0.4, 0.593*0.3, 0.593*0.2, 0.593*0.15, 0.593*0.1, 0.593*0.075, 0.593*0.05)
epsilon_AMR <- c(avg_hum_res*1, avg_hum_res*0.8, avg_hum_res*0.6, avg_hum_res*0.4, avg_hum_res*0.3, avg_hum_res*0.2, avg_hum_res*0.15, avg_hum_res*0.1, avg_hum_res*0.075, avg_hum_res*0.05)
#Run the model
start_time <- Sys.time()
dist_save <- ABC_algorithm(N = 1000,
G = 10,
sum.stats = summarystatprev,
distanceABC = sum_square_diff_dist,
fitmodel = amr,
tau_range = melt_amp_broil$Usage,
init.state = c(Sa=0.98, Isa=0.01, Ira=0.01, Sh=1, Ish=0, Irh=0),
data = melt_amp_broil)
end_time <- Sys.time(); end_time - start_time
saveRDS(dist_save, file = "//csce.datastore.ed.ac.uk/csce/biology/users/s1678248/PhD/Chapter_2/Models/Chapter-2/NewFits_041021/data/new/full/dist_ampbroil_list.rds")
library("deSolve"); library("ggplot2"); library("plotly"); library("reshape2")
library("bayestestR"); library("tmvtnorm"); library("ggpubr"); library("rootSolve")
rm(list=ls())
setwd("//csce.datastore.ed.ac.uk/csce/biology/users/s1678248/PhD/Chapter_2/Models/Chapter-2/NewFits_041021/data")
#Model
amr <- function(t, y, parms) {
with(as.list(c(y, parms)), {
dSa = ua + ra*(Isa + Ira) + kappa*tau*Isa - (betaAA*Isa*Sa) - (betaAH*Ish*Sa) - (1-alpha)*(betaAH*Irh*Sa) - (1-alpha)*(betaAA*Ira*Sa) - ua*Sa -
(0.5*zeta)*Sa*(1-alpha) - (0.5*zeta)*Sa
dIsa = betaAA*Isa*Sa + betaAH*Ish*Sa + phi*Ira - kappa*tau*Isa - tau*Isa - ra*Isa - ua*Isa + (0.5*zeta)*Sa
dIra = (1-alpha)*betaAH*Irh*Sa + (1-alpha)*betaAA*Ira*Sa + tau*Isa - phi*Ira - ra*Ira - ua*Ira + (0.5*zeta)*Sa*(1-alpha)
dSh = uh + rh*(Ish+Irh) - (betaHH*Ish*Sh) - (1-alpha)*(betaHH*Irh*Sh) - (betaHA*Isa*Sh) - (1-alpha)*(betaHA*Ira*Sh) - uh*Sh
dIsh = betaHH*Ish*Sh + betaHA*Isa*Sh - rh*Ish - uh*Ish
dIrh = (1-alpha)*(betaHH*Irh*Sh) + (1-alpha)*(betaHA*Ira*Sh) - rh*Irh - uh*Irh
CumS = betaHH*Ish*Sh + betaHA*Isa*Sh
CumR = (1-alpha)*(betaHH*Irh*Sh) + (1-alpha)*(betaHA*Ira*Sh)
return(list(c(dSa,dIsa,dIra,dSh,dIsh,dIrh), CumS, CumR))
})
}
#### Data Import ####
#Import Data
dataamp_broil <- read.csv("Amp_Broil_Comb.csv")
dataamp_hum <- read.csv("Hum_Broil.csv")
#Cleaning Data - Animals
dataamp_broil[,(2+4):(5+4)][dataamp_broil[,2:5] < 10] <- NA #If N > 10, replace the particular country/year with NA for the No. of pos isolates
dataamp_broil[,(2+8):(5+8)][dataamp_broil[,2:5] < 10] <- NA #If N > 10, replace the particular country/year with NA for the prop of resistant isolates
dataamp_broil[,2:5][dataamp_broil[,2:5] < 10] <- NA #If N > 10, replace the particular country/year with NA for N
dataamp_broil <- dataamp_broil[!(is.na(dataamp_broil$N_2014) & is.na(dataamp_broil$N_2016) & is.na(dataamp_broil$N_2017) &
is.na(dataamp_broil$N_2018)),]
broil_yrs <- sub("N_", "", grep("N_20",colnames(dataamp_broil), value = TRUE)) #Find years of the EFSA and ESVAC data in the dataset
# NON-AGGREGATED - AMP PIGS  -------------------------------------------------------------
colnames(dataamp_broil)[10:13] <- broil_yrs
#Create dataset where each row is a different observation.
melt_amp_broil <- melt(dataamp_broil, id.vars = "Country", measure.vars = broil_yrs)
melt_amp_broil$usage <- melt(dataamp_broil, id.vars = "Country", measure.vars = c("scale_ampusage_2014", "scale_ampusage_2016",
"scale_ampusage_2017", "scale_ampusage_2018"))[,3]
melt_amp_broil$N <- melt(dataamp_broil, id.vars = "Country", measure.vars = c("N_2014", "N_2016",
"N_2017", "N_2018"))[,3]
melt_amp_broil$IsolPos <- melt(dataamp_broil, id.vars = "Country", measure.vars = c("PosIsol_2014", "PosIsol_2016",
"PosIsol_2017", "PosIsol_2018"))[,3]
colnames(melt_amp_broil)[c(2,3)] <- c("Year", "Resistance")
#Cleaning Data - Humans
#only include countries/years which are present in the resistance dataset
dataamp_hum <- dataamp_hum[dataamp_hum$Country %in% intersect(dataamp_hum$Country, dataamp_broil$Country),]
colnames(dataamp_hum)[26:31] <- as.character(2014:2019)
dataamp_hum_melt <- melt(dataamp_hum, id.vars = "Country", measure.vars = broil_yrs)
colnames(dataamp_hum_melt)[c(2,3)] <- c("Year", "Resistance")
# Combine Human and Livestock Dataset -----------------------------------------------------------------
melt_amp_broil$ResPropHum <- dataamp_hum_melt[,3] #Obtain the melted human resistances
melt_amp_broil <- melt_amp_broil[!is.na(melt_amp_broil$Resistance),]
melt_amp_broil <- melt_amp_broil[!is.na(melt_amp_broil$usage),] # Remove all rows with NAs for usage and resistance
#Add 95% CIs for each datapoint
melt_amp_broil$lower_tet <- unlist(lapply(1:nrow(melt_amp_broil), function(i) prop.test(melt_amp_broil$IsolPos[i],melt_amp_broil$N[i])[[6]][[1]]))
melt_amp_broil$upper_tet <- unlist(lapply(1:nrow(melt_amp_broil), function(i) prop.test(melt_amp_broil$IsolPos[i],melt_amp_broil$N[i])[[6]][[2]]))
#Rename the columns
colnames(melt_amp_broil) <- c("Country", "Year", "ResPropAnim", "Usage", "N", "IsolPos", "ResPropHum", "Lower_Tet", "Upper_Tet")
melt_amp_broil$Usage <- melt_amp_broil$Usage/1000 #Change from mg/PCU to g/PCU
ggplot(melt_amp_broil, aes(x = Usage, y= ResPropAnim, color = Country)) + geom_point() +
scale_x_continuous(expand = c(0, 0)) + scale_y_continuous(expand = c(0, 0), limits = c(0,1)) +
labs(x ="Livestock Antibiotic Usage (g/PCU)", y = "Antibiotic-Resistant Livestock Carriage")
#Find the average EU antibiotic usage and average human resistance for model fitting
avg_EU_usage <- mean(melt_amp_broil$Usage)
avg_hum_res <- mean(melt_amp_broil$ResPropHum, na.rm = TRUE)
#### Approximate Bayesian Computation - Rejection Algorithm ####
#Obtain the Resistance
summarystatprev <- function(prev) {
return(prev$ResPropAnim)
}
#Return the sum of squares between resistance and the model output
sum_square_diff_dist <- function(sum.stats, data.obs, model.obs) {
sumsquare <- sapply(sum.stats, function(x) {
sumsquare <- (x(data.obs) - x(model.obs))^2
})
return(sum(sumsquare))
}
#Compute the distances for all 3 summary statistics - this section involves running the model
computeDistanceABC_ALEX <- function(sum.stats, distanceABC, fitmodel, tau_range, thetaparm, init.state, data) {
tauoutput <-data.frame(matrix(nrow = length(tau_range), ncol=4))
tau_range <- append(tau_range, avg_EU_usage)
for (i in 1:length(tau_range)) {
parms2 = thetaparm
parms2["tau"] = tau_range[i]
out <- runsteady(y = init.state, func = fitmodel, times = c(0, Inf), parms = parms2)
>>>>>>> Stashed changes
tauoutput[i,] <- c(tau_range[i],
((out[[2]] + out[[3]])*(446000000))/100000,
out[[1]][["Ira"]] / (out[[1]][["Isa"]] + out[[1]][["Ira"]]),
out[[1]][["Irh"]] / (out[[1]][["Ish"]] + out[[1]][["Irh"]]))
}
tauoutput <- data.frame(tauoutput)
colnames(tauoutput) <- c("tau", "IncH", "ResPropAnim", "ResPropHum")
<<<<<<< Updated upstream
# Plot Tau range ----------------------------------------------------------
ggplot(melt_amp_broil, aes(x = Usage, y= ResPropAnim, color = Country))  + geom_point() + theme_bw() +
scale_x_continuous(expand = c(0, 0)) + scale_y_continuous(expand = c(0, 0), limits = c(0,1)) +
labs(x ="Pig Ampicillin Sales (g/PCU)", y = "Ampicillin-Resistant Pig Carriage") +
geom_line(data = tauoutput, aes(x = tau, y= ResPropAnim), col = "red", size = 1.1) +
theme(legend.text=element_text(size=12), axis.text=element_text(size=12),
axis.title.y=element_text(size=12), axis.title.x= element_text(size=12), plot.margin = unit(c(1,1,1,1), "cm"))
ggplot(tauoutput, aes(x = tau, y= IncH)) +
scale_x_continuous(expand = c(0, 0)) + scale_y_continuous(expand = c(0, 0), limits = c(0,1)) +
labs(x ="Pig Ampicillin Sales (g/PCU)", y = "Daily Human Incidence") +
geom_line(col = "red", size = 1.1) + geom_vline(xintercept = avg_EU_usage, lty = 2, col = "red") +
geom_hline(yintercept = 0.593, lty = 2, col = "red") +
theme(legend.text=element_text(size=12), axis.text=element_text(size=12),
axis.title.y=element_text(size=12), axis.title.x= element_text(size=12), plot.margin = unit(c(1,1,1,1), "cm"))
ggplot(tauoutput, aes(x = tau, y= ResPropHum)) +
scale_x_continuous(expand = c(0, 0)) + scale_y_continuous(expand = c(0, 0), limits = c(0,1)) +
labs(x ="Pig Ampicillin Sales (g/PCU)", y = "Proportion of Human Resistance") +
geom_line(col = "red", size = 1.1) + geom_vline(xintercept = avg_EU_usage, lty = 2, col = "red") +
geom_hline(yintercept = avg_hum_res, lty = 2, col = "red") +
theme(legend.text=element_text(size=12), axis.text=element_text(size=12),
axis.title.y=element_text(size=12), axis.title.x= element_text(size=12), plot.margin = unit(c(1,1,1,1), "cm"))
=======
return(c(distanceABC(list(sum.stats), data, tauoutput[!tauoutput$tau == avg_EU_usage,]),
abs(tauoutput$IncH[tauoutput$tau == avg_EU_usage] - 0.593),
abs(tauoutput$ResPropHum[tauoutput$tau == avg_EU_usage] - avg_hum_res)))
}
#Where G is the number of generations
#Function to 100% make sure the sampled particles for all parameters are non zero
prior.non.zero<-function(par){
prod(sapply(1:6, function(a) as.numeric((par[a]-lm.low[a]) > 0) * as.numeric((lm.upp[a]-par[a]) > 0)))
}
#Wrapper function for all of the functions to output the distance measures and the diagnostics
#Saving of the accepted particles in each generation done within the function
ABC_algorithm <- function(N, G, sum.stats, distanceABC, fitmodel, tau_range, init.state, data)  {
N_ITER_list <- list()
fit_parms <- c("betaAA", "phi", "kappa", "alpha", "zeta", "betaHA")
thetaparm <- c(ra = 0, rh = (5.5^-1), ua = 42^-1, uh = 28835^-1, betaAH = 0.00001, betaHH = 0.00001)
for(g in 1:G) {
i <- 1
dist_data <- data.frame(matrix(nrow = 1000, ncol = 3))
N_ITER <- 1
while(i <= N) {
N_ITER <- N_ITER + 1
if(g==1) {
d_betaAA <- runif(1, min = 0, max = 0.25)
d_phi <- runif(1, min = 0, max = 0.1)
d_kappa <- runif(1, min = 0, max = 2)
d_alpha <- rbeta(1, 1.5, 8.5)
d_zeta <- runif(1, 0, 1.5)
d_betaHA <- runif(1, 0, 0.0005)
} else{
p <- sample(seq(1,N),1,prob= w.old) # check w.old here
par <- rtmvnorm(1, mean=res.old[p,], sigma=sigma, lower=lm.low, upper=lm.upp)
d_betaAA<-par[1]
d_phi<-par[2]
d_kappa<-par[3]
d_alpha<-par[4]
d_zeta <- par[5]
d_betaHA <-par[6]
}
if(prior.non.zero(c(d_betaAA, d_phi, d_kappa, d_alpha, d_zeta, d_betaHA))) {
m <- 0
thetaparm <- c(ra = 0, rh = (5.5^-1), ua = 42^-1, uh = 28835^-1, betaAA = d_betaAA, betaAH = 0.00001, betaHH = 0.00001,
betaHA = d_betaHA, phi = d_phi, kappa = d_kappa, alpha = d_alpha, zeta = d_zeta)
dist <- computeDistanceABC_ALEX(sum.stats, distanceABC, fitmodel, tau_range, thetaparm, init.state, data)
print(dist)
if((dist[1] <= epsilon_dist[g]) && (dist[2] <= epsilon_food[g]) && (dist[3] <= epsilon_AMR[g]) && (!is.na(dist))) {
# Store results
res.new[i,]<-c(d_betaAA, d_phi, d_kappa, d_alpha, d_zeta, d_betaHA)
dist_data[i,] <- dist
# Calculate weights
if(g==1){
w.new[i] <- 1
} else {
w1<-prod(c(sapply(c(1:3,5:6), function(b) dunif(res.new[i,b], min=lm.low[b], max=lm.upp[b])),
dbeta(res.new[i,4], 1.5, 8.5)))
w2<-sum(sapply(1:N, function(a) w.old[a]* dtmvnorm(res.new[i,], mean=res.old[a,], sigma=sigma, lower=lm.low, upper=lm.upp)))
w.new[i] <- w1/w2
}
# Update counter
print(paste0('Generation: ', g, ", particle: ", i,", weights: ", w.new[i]))
print(dist)
i <- i+1
}
}
}
N_ITER_list[[g]] <- list(N_ITER, dist_data)
sigma <- cov(res.new)
res.old <- res.new
print(res.old)
w.old <- w.new/sum(w.new)
colnames(res.new) <- c("betaAA", "phi", "kappa", "alpha", "zeta", "betaHA")
write.csv(res.new, file = paste("//csce.datastore.ed.ac.uk/csce/biology/users/s1678248/PhD/Chapter_2/Models/Chapter-2/NewFits_041021/data/new/full/ABC_post_ampbroil_",g,".csv",sep=""), row.names=FALSE)
}
return(N_ITER_list)
}
N <- 1000 #(ACCEPTED PARTICLES PER GENERATION)
lm.low <- c(0, 0, 0, 0, 0, 0)
lm.upp <- c(0.25, 0.1, 2, 1, 1.5, 0.0005) #Upper and lower bounds for the priors - for the multivariate normal dist pert kernel
# Empty matrices to store results (6 model parameters)
res.old<-matrix(ncol=6,nrow=N)
res.new<-matrix(ncol=6,nrow=N)
# Empty vectors to store weights
w.old<-matrix(ncol=1,nrow=N)
w.new<-matrix(ncol=1,nrow=N)
#Thresholds
epsilon_dist <-  c(5, 4, 3.5, 3.25, 3, 2.5, 2.25, 2.1, 2, 1.96)
epsilon_food <- c(0.593*1, 0.593*0.8, 0.593*0.6, 0.593*0.4, 0.593*0.3, 0.593*0.2, 0.593*0.15, 0.593*0.1, 0.593*0.075, 0.593*0.05)
epsilon_AMR <- c(avg_hum_res*1, avg_hum_res*0.8, avg_hum_res*0.6, avg_hum_res*0.4, avg_hum_res*0.3, avg_hum_res*0.2, avg_hum_res*0.15, avg_hum_res*0.1, avg_hum_res*0.075, avg_hum_res*0.05)
#Run the model
start_time <- Sys.time()
dist_save <- ABC_algorithm(N = 1000,
G = 10,
sum.stats = summarystatprev,
distanceABC = sum_square_diff_dist,
fitmodel = amr,
tau_range = melt_amp_broil$Usage,
init.state = c(Sa=0.98, Isa=0.01, Ira=0.01, Sh=1, Ish=0, Irh=0),
data = melt_amp_broil)
end_time <- Sys.time(); end_time - start_time
saveRDS(dist_save, file = "//csce.datastore.ed.ac.uk/csce/biology/users/s1678248/PhD/Chapter_2/Models/Chapter-2/NewFits_041021/data/new/full/dist_ampbroil_list.rds")
>>>>>>> Stashed changes
